{"cells":[{"metadata":{},"cell_type":"markdown","source":"Deep convolutional GANs\n\nWe will try using a DCGANs to generate pictures from the Fashion MNIST dataset."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import sklearn\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport pandas as pd\nimport os\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"pip install tensorflow==2.0.0-beta1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's set up the fashion MNIST dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\nX_train_full = X_train_full.astype(np.float32) / 255\nX_test = X_test.astype(np.float32) / 255\nX_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\ny_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's also set up a Deep Convolutional GANs"},{"metadata":{"trusted":true},"cell_type":"code","source":"codings_size = 100 \n \ngenerator = keras.models.Sequential([ \n    keras.layers.Dense(7 * 7 * 128, input_shape=[codings_size]), \n    keras.layers.Reshape([7, 7, 128]), \n    keras.layers.BatchNormalization(), \n    keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"same\", \n                                 activation=\"selu\"), \n    keras.layers.BatchNormalization(), \n    keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2, padding=\"same\", \n                                 activation=\"tanh\")\n])\ndiscriminator = keras.models.Sequential([ \n    keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"same\", \n                        activation=keras.layers.LeakyReLU(0.2), \n                        input_shape=[28, 28, 1]), \n    keras.layers.Dropout(0.4), \n    keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"same\", \n                        activation=keras.layers.LeakyReLU(0.2)), \n    keras.layers.Dropout(0.4), \n    keras.layers.Flatten(), \n    keras.layers.Dense(1, activation=\"sigmoid\")\n])\ngan = keras.models.Sequential([generator, discriminator])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The generator takes a random distribution input (usually Gaussian) and outputs data (usually images).\n\nThe Discriminator takes real images from training set or fake images from the generator as input and must guess if real or fake."},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\ndiscriminator.trainable = False\ngan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use binary cross entropy loss since both our discriminator and our GAN are binary classifiers.\n\nDiscriminator should only be trained during second phase. This attribute is only taken into account when compiling the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_dcgan = X_train.reshape(-1, 28, 28, 1) * 2. - 1.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our generator's output layer uses tanh activation so our output ranges from -1 to 1. We need to rescale our training set to the same range before training."},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\ndataset = tf.data.Dataset.from_tensor_slices(X_train_dcgan)\ndataset = dataset.shuffle(1000)\ndataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We create a dataset to iterate through images.\n\nWe cannot use regular fit since we have an uncommon training loop so we create our own."},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50): \n    generator, discriminator = gan.layers \n    for epoch in range(n_epochs): \n        for X_batch in dataset:\n            noise = tf.random.normal(shape=[batch_size, codings_size]) \n            generated_images = generator(noise) \n            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0) \n            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size) \n            discriminator.trainable = True \n            discriminator.train_on_batch(X_fake_and_real, y1) \n            noise = tf.random.normal(shape=[batch_size, codings_size]) \n            y2 = tf.constant([[1.]] * batch_size) \n            discriminator.trainable = False \n            gan.train_on_batch(noise, y2) \n \ntrain_gan(gan, dataset, batch_size, codings_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We feed Gaussian noise to produce fake images and concatenate and equal number of real images.\n\nThe discriminator tries to guess which images are fake and which images are real.\n\nLet's try the same example with Hashing using a Binary Autoencoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rounded_accuracy(y_true, y_pred):\n    return keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))\n\nhashing_encoder = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[28, 28]),\n    keras.layers.Dense(100, activation=\"selu\"),\n    keras.layers.GaussianNoise(15.),\n    keras.layers.Dense(16, activation=\"sigmoid\"),\n])\nhashing_decoder = keras.models.Sequential([\n    keras.layers.Dense(100, activation=\"selu\", input_shape=[16]),\n    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n    keras.layers.Reshape([28, 28])\n])\nhashing_ae = keras.models.Sequential([hashing_encoder, hashing_decoder])\nhashing_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(lr=1.0),\n                   metrics=[rounded_accuracy])\nhistory = hashing_ae.fit(X_train, X_train, epochs=10,\n                         validation_data=[X_valid, X_valid])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model is split into two part: the hashing encoder and the hashing decoder.\n\nThis encoder take 28x28 grayscale images and outputs it as a vector of size 16.\n\nThis decoder takes an input of size 16 and outputs 28x28 arrays.\n\nWe use binary cross-entropy again because we treat the model as a multilabel binary classification problem for faster convergence(pixel intensity represents probability that pixel should be black)."},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_reconstructions(model, images=X_valid, n_images=5):\n    reconstructions = model.predict(images[:n_images])\n    fig = plt.figure(figsize=(n_images * 1.5, 3))\n    for image_index in range(n_images):\n        plt.subplot(2, n_images, 1 + image_index)\n        plot_image(images[image_index])\n        plt.subplot(2, n_images, 1 + n_images + image_index)\n        plot_image(reconstructions[image_index])\n\ndef plot_image(image):\n    plt.imshow(image, cmap=\"binary\")\n    plt.axis(\"off\")\n        \nshow_reconstructions(hashing_ae)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We compare inputs with outputs. \n\nOur outputs are a bit blurry and we should probably train our model a bit more or make the both the encoder and decoder with more layers.\n\nIf we make the model too strong, our outputs would be better but it wouldn't learn the useful patterns of the data so we will leave the model as is."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}